def get_report_visits_yandex_metric(arguments: dict) -> str:
    """
    –§–æ—Ä–º–∏—Ä—É–µ—Ç –æ—Ç—á—ë—Ç –∏–∑ –Ø–Ω–¥–µ–∫—Å.–ú–µ—Ç—Ä–∏–∫–∏ (Reports API) –≤ —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–º —Ä–µ–∂–∏–º–µ
    –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ –≤–∏–¥–µ —Å—Ç—Ä–æ–∫–∏ (CSV –∏–ª–∏ JSON).

    Args:
        arguments (dict): —Å–ª–æ–≤–∞—Ä—å –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤.

        –û—Å–Ω–æ–≤–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã (–±–æ–µ–≤—ã–µ, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç API –ú–µ—Ç—Ä–∏–∫–∏):
            - ids (str): ID —Å—á—ë—Ç—á–∏–∫–∞ (**–æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–π**).
            - date1 (str, —Ñ–æ—Ä–º–∞—Ç YYYY-MM-DD): –Ω–∞—á–∞–ª—å–Ω–∞—è –¥–∞—Ç–∞ –ø–µ—Ä–∏–æ–¥–∞.
            - date2 (str, —Ñ–æ—Ä–º–∞—Ç YYYY-MM-DD): –∫–æ–Ω–µ—á–Ω–∞—è –¥–∞—Ç–∞ –ø–µ—Ä–∏–æ–¥–∞.
            - metrics (str, optional): —Å–ø–∏—Å–æ–∫ –º–µ—Ç—Ä–∏–∫ —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é.
            - dimensions (str, optional): —Å–ø–∏—Å–æ–∫ –≥—Ä—É–ø–ø–∏—Ä–æ–≤–æ–∫ —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é.
            - filters (str, optional): —Å—Ç—Ä–æ–∫–∞ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏.
            - preset (str, optional): –Ω–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–µ–¥—É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω–æ–≥–æ –æ—Ç—á—ë—Ç–∞.
            - sort (str, optional): –ø–æ–ª–µ —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä "-ym:s:pageviews").
            - lang (str, optional): —è–∑—ã–∫ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é "en").
            - token (str, optional): OAuth‚Äë—Ç–æ–∫–µ–Ω.

        –ù–∞–¥—Å—Ç—Ä–æ–π–∫–∏ / —Ç–µ—Å—Ç–æ–≤—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã (—Å–ª—É–∂–µ–±–Ω—ã–µ, –Ω–µ —è–≤–ª—è—é—Ç—Å—è —á–∞—Å—Ç—å—é API, –∞ —É–ø—Ä–∞–≤–ª—è—é—Ç –ª–æ–≥–∏–∫–æ–π –≤—ã–≥—Ä—É–∑–∫–∏):
            - split (bool, optional): –≤–∫–ª—é—á–∏—Ç—å –∞–≤—Ç–æ‚Äë–¥—Ä–æ–±–ª–µ–Ω–∏–µ –¥–∏–∞–ø–∞–∑–æ–Ω–∞ –¥–∞—Ç (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é True).
            - timeout (int, optional): –æ–±—â–∏–π –ª–∏–º–∏—Ç –≤—Ä–µ–º–µ–Ω–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —Ñ—É–Ω–∫—Ü–∏–∏ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 60).
                ‚Ä¢ –í—Å–µ –ø–æ–¥–∑–∞–ø—Ä–æ—Å—ã –¥–µ–ª—è—Ç —ç—Ç–æ—Ç –ª–∏–º–∏—Ç; –µ—Å–ª–∏ –æ–Ω –∏—Å—á–µ—Ä–ø–∞–Ω ‚Äî –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –ø—Ä–µ—Ä—ã–≤–∞–µ—Ç—Å—è.
            - batch_size (int, optional): –ª–∏–º–∏—Ç —Å—Ç—Ä–æ–∫ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 10000).
            - max_rows (int, optional): –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫ –¥–ª—è –≤—ã–≥—Ä—É–∑–∫–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –±–µ–∑ –ª–∏–º–∏—Ç–∞).
            - output_format (str, optional): —Ñ–æ—Ä–º–∞—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞: "csv" –∏–ª–∏ "json" (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é "csv").

    Returns:
        str: —Ä–µ–∑—É–ª—å—Ç–∞—Ç –æ—Ç—á—ë—Ç–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ CSV –∏–ª–∏ JSON (–≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä–∞ output_format).

    –ó–∞–º–µ—á–∞–Ω–∏—è:
        * –ï—Å–ª–∏ –∑–∞–¥–∞–Ω—ã metrics –∏ dimensions ‚Äî –æ–Ω–∏ –ø–µ—Ä–µ–∫—Ä—ã–≤–∞—é—Ç preset (—Ä–∞–±–æ—Ç–∞–µ—Ç —Ä—É—á–Ω–æ–π —Ä–µ–∂–∏–º).
        * –í –ø–∞—Ä–∞–º–µ—Ç—Ä–µ filters –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ç–æ–ª—å–∫–æ dimensions, –º–µ—Ç—Ä–∏–∫–∏ —Ç–∞–º –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è.
        * –í –ø–∞—Ä–∞–º–µ—Ç—Ä–µ sort –º–æ–∂–Ω–æ —É–∫–∞–∑—ã–≤–∞—Ç—å —Ç–æ–ª—å–∫–æ –ø–æ–ª—è, –∫–æ—Ç–æ—Ä—ã–µ —Ä–µ–∞–ª—å–Ω–æ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç –≤ metrics –∏–ª–∏ dimensions.
        * API –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –º–∞–∫—Å–∏–º—É–º 10000 —Å—Ç—Ä–æ–∫ –∑–∞ –æ–¥–∏–Ω –∑–∞–ø—Ä–æ—Å; –¥–ª—è –±–æ–ª—å—à–∏—Ö –≤—ã–±–æ—Ä–æ–∫ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è offset.
        * –î–∞–∂–µ –ø—Ä–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏ offset –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫ –º–æ–∂–µ—Ç –±—ã—Ç—å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–æ —Å–∞–º–∏–º API.
        * –ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø–µ—Ä–∏–æ–¥—ã (comparisonMode) –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è.
        * –ï—Å–ª–∏ API –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ –∫–∞–∫ –≤–ª–æ–∂–µ–Ω–Ω—ã–µ —Å–ø–∏—Å–∫–∏ ([[...]]),
          —Ñ—É–Ω–∫—Ü–∏—è –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–π –º–∞—Å—Å–∏–≤ –∑–Ω–∞—á–µ–Ω–∏–π.
          –ü–æ–¥–¥–µ—Ä–∂–∫–∞ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –Ω–∞–±–æ—Ä–æ–≤ –º–µ—Ç—Ä–∏–∫ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –ø—Ä–∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏–∏ –ø–µ—Ä–∏–æ–¥–æ–≤) –Ω–µ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–∞.
        * –ü–∞—Ä–∞–º–µ—Ç—Ä—ã split, timeout, batch_size, max_rows –∏ output_format —è–≤–ª—è—é—Ç—Å—è –Ω–∞–¥—Å—Ç—Ä–æ–π–∫–∞–º–∏ —Ñ—É–Ω–∫—Ü–∏–∏
          –∏ –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è –Ω–∞–ø—Ä—è–º—É—é API –ú–µ—Ç—Ä–∏–∫–∏.
        * –ï—Å–ª–∏ —Å—á—ë—Ç—á–∏–∫ –ø—Ä–∏–≤–∞—Ç–Ω—ã–π –∏ —Ç–æ–∫–µ–Ω –Ω–µ —É–∫–∞–∑–∞–Ω ‚Äî –∑–∞–ø—Ä–æ—Å –∑–∞–≤–µ—Ä—à–∏—Ç—Å—è –æ—à–∏–±–∫–æ–π –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏.
        * –ï—Å–ª–∏ —Å—á—ë—Ç—á–∏–∫ –ø—É–±–ª–∏—á–Ω—ã–π ‚Äî –º–æ–∂–Ω–æ —Ä–∞–±–æ—Ç–∞—Ç—å –±–µ–∑ —Ç–æ–∫–µ–Ω–∞.
        * –¢–∞–π–º–∞—É—Ç –∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É–µ—Ç—Å—è –≥–ª–æ–±–∞–ª—å–Ω–æ: –≤—Å–µ –ø–æ–¥–∑–∞–ø—Ä–æ—Å—ã –¥–µ–ª—è—Ç –æ–¥–∏–Ω –æ–±—â–∏–π –ª–∏–º–∏—Ç –≤—Ä–µ–º–µ–Ω–∏.

    """

    # def upload_to_tmpfiles(df: pd.DataFrame, output_format: str = "csv") -> str:
    #     """
	# 	–°–æ—Ö—Ä–∞–Ω—è–µ—Ç DataFrame –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –∏ –∑–∞–≥—Ä—É–∂–∞–µ—Ç –µ–≥–æ –Ω–∞ tmpfiles.org
	# 	"""
    #
    # def fetch_chunk_all_pages_streaming(url, params, headers, batch_size, output_format="csv", file_path="report.csv"):
    #     """
	# 	–°—Ç—Ä–∏–º–∏–Ω–≥–æ–≤–∞—è –≤—ã–≥—Ä—É–∑–∫–∞: –ø–æ—Å—Ç—Ä–∞–Ω–∏—á–Ω–æ –ø–∏—à–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ —Ñ–∞–π–ª (CSV –∏–ª–∏ NDJSON),
	# 	–Ω–µ –Ω–∞–∫–∞–ø–ª–∏–≤–∞—è –≤—Å–µ —Å—Ç—Ä–æ–∫–∏ –≤ –ø–∞–º—è—Ç–∏.
	# 	"""

    import os
    import requests
    import pandas as pd
    import json
    import logging
    import time
    from datetime import datetime, timedelta

    # --- –ö–ª–∞—Å—Å –∏—Å–∫–ª—é—á–µ–Ω–∏–π ---
    class YandexMetrikaError(Exception):
        """–°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∏—Å–∫–ª—é—á–µ–Ω–∏–µ –¥–ª—è –æ—à–∏–±–æ–∫ —Ä–∞–±–æ—Ç—ã —Å API –Ø–Ω–¥–µ–∫—Å.–ú–µ—Ç—Ä–∏–∫–∏"""
        pass

    # --- –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è ---
    log_level = arguments.get("log_level", "INFO").upper()
    logging.basicConfig(
        level=getattr(logging, log_level, logging.INFO),
        format="%(asctime)s [%(levelname)s] %(message)s"
    )

    API_URL = "https://api-metrika.yandex.net/stat/v1/data"
    start_time = time.perf_counter()  # ‚è± —Å—Ç–∞—Ä—Ç –∑–∞–º–µ—Ä–∞ –æ–±—â–µ–≥–æ –≤—Ä–µ–º–µ–Ω–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
    global_timeout = int(arguments.get("timeout", 60))  # –æ–±—â–∏–π –ª–∏–º–∏—Ç –≤—Ä–µ–º–µ–Ω–∏ –Ω–∞ –≤—Å—é —Ñ—É–Ω–∫—Ü–∏—é

    # --- –§—É–Ω–∫—Ü–∏—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –æ—Å—Ç–∞—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–∏ ---
    def remaining_timeout() -> float:
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–µ–∫—É–Ω–¥, –æ—Å—Ç–∞–≤—à–∏—Ö—Å—è –¥–æ –∏—Å—Ç–µ—á–µ–Ω–∏—è –≥–ª–æ–±–∞–ª—å–Ω–æ–≥–æ –ª–∏–º–∏—Ç–∞.
        –ï—Å–ª–∏ –ª–∏–º–∏—Ç –∏—Å—á–µ—Ä–ø–∞–Ω ‚Äî –≤—ã–±—Ä–∞—Å—ã–≤–∞–µ—Ç –∏—Å–∫–ª—é—á–µ–Ω–∏–µ.
        """
        elapsed = time.perf_counter() - start_time
        left = global_timeout - elapsed
        if left <= 0:
            raise YandexMetrikaError("–ü—Ä–µ–≤—ã—à–µ–Ω –æ–±—â–∏–π –ª–∏–º–∏—Ç –≤—Ä–µ–º–µ–Ω–∏ –Ω–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∞")
        return left

    # --- –†–∞–∑–±–∏–µ–Ω–∏–µ –¥–∏–∞–ø–∞–∑–æ–Ω–∞ –¥–∞—Ç –Ω–∞ —á–∞–Ω–∫–∏ ---
    def auto_date_chunks(date1: str, date2: str, split: bool = True):
        """
        –î–µ–ª–∏—Ç –¥–∏–∞–ø–∞–∑–æ–Ω –¥–∞—Ç –Ω–∞ –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ —á–∞–Ω–∫–∏:
          - –¥–æ 365 –¥–Ω–µ–π ‚Üí –º–µ—Å—è—Ü—ã
          - –¥–æ 5 –ª–µ—Ç ‚Üí –∫–≤–∞—Ä—Ç–∞–ª—ã
          - –±–æ–ª—å—à–µ 5 –ª–µ—Ç ‚Üí –≥–æ–¥—ã
        """
        try:
            start = datetime.strptime(date1, "%Y-%m-%d")
            end = datetime.strptime(date2, "%Y-%m-%d")
        except ValueError as e:
            raise YandexMetrikaError(f"–ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–∞—Ç—ã: {e}")

        if start > end:
            raise YandexMetrikaError("date1 –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –±–æ–ª—å—à–µ date2")

        if not split:
            yield date1, date2
            return

        delta_days = (end - start).days

        # –¥–æ 1 –≥–æ–¥–∞ ‚Üí –º–µ—Å—è—Ü—ã
        if delta_days <= 365:
            while start <= end:
                next_month = (start.replace(day=28) + timedelta(days=4)).replace(day=1)
                chunk_end = min(next_month - timedelta(days=1), end)
                yield start.strftime("%Y-%m-%d"), chunk_end.strftime("%Y-%m-%d")
                start = next_month

        # –¥–æ 5 –ª–µ—Ç ‚Üí –∫–≤–∞—Ä—Ç–∞–ª—ã
        elif delta_days <= 1825:
            while start <= end:
                # –≤—ã—á–∏—Å–ª—è–µ–º –Ω–∞—á–∞–ª–æ —Å–ª–µ–¥—É—é—â–µ–≥–æ –∫–≤–∞—Ä—Ç–∞–ª–∞
                month = ((start.month - 1) // 3 + 1) * 3 + 1
                year = start.year
                if month > 12:
                    month = 1
                    year += 1
                next_quarter = datetime(year, month, 1)
                chunk_end = min(next_quarter - timedelta(days=1), end)
                yield start.strftime("%Y-%m-%d"), chunk_end.strftime("%Y-%m-%d")
                start = next_quarter

        # –±–æ–ª—å—à–µ 5 –ª–µ—Ç ‚Üí –≥–æ–¥—ã
        else:
            while start <= end:
                next_year = start.replace(month=1, day=1, year=start.year + 1)
                chunk_end = min(next_year - timedelta(days=1), end)
                yield start.strftime("%Y-%m-%d"), chunk_end.strftime("%Y-%m-%d")
                start = next_year

    # --- –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ DataFrame –∏–∑ –æ—Ç–≤–µ—Ç–∞ API ---
    def build_dataframe(data: dict) -> pd.DataFrame:
        """
        –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç JSON-–æ—Ç–≤–µ—Ç API –≤ pandas.DataFrame.
        –ö–æ—Ä—Ä–µ–∫—Ç–Ω–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –≤–ª–æ–∂–µ–Ω–Ω—ã–µ –º–∞—Å—Å–∏–≤—ã metrics.
        """
        query = data.get("query", {}) or {}
        dim_names = [d.split(":")[-1] for d in query.get("dimensions", [])]
        met_names = [m.split(":")[-1] for m in query.get("metrics", [])]

        rows = []
        for row in data.get("data", []):
            record = {}
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ dimensions
            for j, dim in enumerate(row.get("dimensions", [])):
                record[dim_names[j] if j < len(dim_names) else f"dimension_{j}"] = dim.get("name")

            # –û–±—Ä–∞–±–æ—Ç–∫–∞ metrics (—É—á—ë—Ç –≤–ª–æ–∂–µ–Ω–Ω—ã—Ö —Å–ø–∏—Å–∫–æ–≤)
            metrics = row.get("metrics", [])
            if metrics and isinstance(metrics[0], list):
                metrics = metrics[0]

            for j, val in enumerate(metrics):
                record[met_names[j] if j < len(met_names) else f"metric_{j}"] = val

            rows.append(record)

        return pd.DataFrame(rows, columns=dim_names + met_names)

    # --- –ó–∞–ø—Ä–æ—Å —Å—Ç—Ä–∞–Ω–∏—Ü—ã ---
    def fetch_page(url, params, headers):
        resp = None
        try:
            resp = requests.get(url, params=params, headers=headers, timeout=remaining_timeout())
            resp.raise_for_status()
            return resp.json()
        except requests.exceptions.Timeout:
            raise YandexMetrikaError("–ü—Ä–µ–≤—ã—à–µ–Ω –æ–±—â–∏–π –ª–∏–º–∏—Ç –≤—Ä–µ–º–µ–Ω–∏ (timeout)")
        except requests.exceptions.ConnectionError:
            raise YandexMetrikaError("–û—à–∏–±–∫–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å API –Ø–Ω–¥–µ–∫—Å.–ú–µ—Ç—Ä–∏–∫–∏")
        except requests.exceptions.HTTPError:
            if resp is not None:
                try:
                    error_json = resp.json()
                    message = (
                        error_json.get("message")
                        or error_json.get("errors", [{}])[0].get("message", "")
                    )
                except Exception:
                    message = resp.text
                code = resp.status_code
                if code == 400:
                    raise YandexMetrikaError(f"[400] –ù–µ–≤–µ—Ä–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∑–∞–ø—Ä–æ—Å–∞: {message}")
                elif code == 401:
                    raise YandexMetrikaError(f"[401] –ù–µ–∞–≤—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω: {message}")
                elif code == 402:
                    raise YandexMetrikaError(f"[402] –ü—Ä–µ–≤—ã—à–µ–Ω–∞ –∫–≤–æ—Ç–∞ –∏–ª–∏ —Ç—Ä–µ–±—É–µ—Ç—Å—è –æ–ø–ª–∞—Ç–∞: {message}")
                elif code == 403:
                    raise YandexMetrikaError(f"[403] –î–æ—Å—Ç—É–ø –∑–∞–ø—Ä–µ—â—ë–Ω: {message}")
                elif code == 404:
                    raise YandexMetrikaError(f"[404] –°—á—ë—Ç—á–∏–∫ –∏–ª–∏ —Ä–µ—Å—É—Ä—Å –Ω–µ –Ω–∞–π–¥–µ–Ω: {message}")
                elif code == 413:
                    raise YandexMetrikaError(f"[413] –°–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π –∑–∞–ø—Ä–æ—Å: {message}")
                elif code == 429:
                    raise YandexMetrikaError(f"[429] –ü—Ä–µ–≤—ã—à–µ–Ω –ª–∏–º–∏—Ç –∑–∞–ø—Ä–æ—Å–æ–≤: {message}")
                elif code >= 500:
                    raise YandexMetrikaError(f"[{code}] –û—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞: {message}")
                else:
                    raise YandexMetrikaError(f"[{code}] –ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞ API: {message}")
            else:
                raise YandexMetrikaError("HTTPError, –Ω–æ –æ–±—ä–µ–∫—Ç –æ—Ç–≤–µ—Ç–∞ –Ω–µ —Å–æ–∑–¥–∞–Ω")
        finally:
            time.sleep(0.11)

    def fetch_chunk_all_pages(url, params, headers, batch_size, max_rows=None):
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç –≤—Å–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –¥–∞–Ω–Ω—ã—Ö (limit+offset) –¥–ª—è –∑–∞–¥–∞–Ω–Ω–æ–≥–æ –¥–∏–∞–ø–∞–∑–æ–Ω–∞ –¥–∞—Ç.
        –£—á–∏—Ç—ã–≤–∞–µ—Ç total_rows –∏ sampled –∏–∑ –æ—Ç–≤–µ—Ç–∞ API.
        """
        all_rows = []
        offset = 1
        query = None
        total_rows = None
        sampled_global = False

        while True:
            p = params.copy()
            p.update({"limit": batch_size, "offset": offset})
            payload = fetch_page(url, p, headers)

            if "data" not in payload:
                raise YandexMetrikaError(f"–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –æ—Ç–≤–µ—Ç API –ø—Ä–∏ offset={offset}: {payload}")

            if query is None:
                query = payload.get("query", {})

            # —á–∏—Ç–∞–µ–º total_rows –∏ sampled
            total_rows = payload.get("total_rows", total_rows)
            if payload.get("sampled"):
                sampled_global = True

            data_rows = payload.get("data", []) or []
            all_rows.extend(data_rows)

            # –ø—Ä–æ–≤–µ—Ä–∫–∞ max_rows
            if max_rows and len(all_rows) >= max_rows:
                logging.warning(f"–î–æ—Å—Ç–∏–≥–Ω—É—Ç –ª–∏–º–∏—Ç max_rows={max_rows}, –æ–±—Ä–µ–∑–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç")
                all_rows = all_rows[:max_rows]
                break

            # ‚úÖ –ï–î–ò–ù–°–¢–í–ï–ù–ù–ê–Ø –ø—Ä–æ–≤–µ—Ä–∫–∞ –æ–∫–æ–Ω—á–∞–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö
            if len(data_rows) < batch_size:
                break

            offset += batch_size

        if sampled_global:
            logging.warning("‚ö†Ô∏è –î–∞–Ω–Ω—ã–µ —É—Å–µ—á–µ–Ω—ã (sampled=True) ‚Äî –æ—Ç—á—ë—Ç –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ–ø–æ–ª–Ω—ã–º")

        return {"query": query, "data": all_rows}

    # --- –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ö–æ–¥–Ω—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ ---
    if not arguments.get("ids"):
        raise YandexMetrikaError("–ù–µ –Ω–∞–π–¥–µ–Ω –ø–∞—Ä–∞–º–µ—Ç—Ä 'ids'")
    if not arguments.get("date1") or not arguments.get("date2"):
        raise YandexMetrikaError("–ù–µ –∑–∞–¥–∞–Ω—ã –¥–∞—Ç—ã (date1/date2)")

    # --- –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∑–∞–ø—Ä–æ—Å–∞ ---
    metrics, dimensions, filters = arguments.get("metrics"), arguments.get("dimensions"), arguments.get("filters")
    preset, sort = arguments.get("preset"), arguments.get("sort")
    lang = arguments.get("lang", "en")
    token = arguments.get("token") or os.getenv("YANDEX_METRIKA_TOKEN")
    split = arguments.get("split", True)
    batch_size = int(arguments.get("batch_size", 10000))
    max_rows = int(arguments.get("max_rows", 0)) or None
    output_format = arguments.get("output_format", "csv")

    use_manual_config = bool(metrics and dimensions)
    params = {"ids": arguments["ids"], "lang": lang, "date1": arguments["date1"], "date2": arguments["date2"]}

    if use_manual_config:
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Å—Ç—Ä–æ–∫–∏ –≤ —Å–ø–∏—Å–∫–∏, —É–±–∏—Ä–∞–µ–º –ø—Ä–æ–±–µ–ª—ã –∏ –ø—É—Å—Ç—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã
        if isinstance(metrics, str):
            params["metrics"] = [m.strip() for m in metrics.split(",") if m.strip()]
        else:
            params["metrics"] = metrics

        if isinstance(dimensions, str):
            params["dimensions"] = [d.strip() for d in dimensions.split(",") if d.strip()]
        else:
            params["dimensions"] = dimensions

        # –§–∏–ª—å—Ç—Ä—ã –ø–µ—Ä–µ–¥–∞—é—Ç—Å—è –∫–∞–∫ —Å—Ç—Ä–æ–∫–∞ (API –ø—Ä–∏–Ω–∏–º–∞–µ—Ç –∏–º–µ–Ω–Ω–æ —Å—Ç—Ä–æ–∫—É)
        if filters:
            params["filters"] = filters
    else:
        # –ï—Å–ª–∏ metrics/dimensions –Ω–µ –∑–∞–¥–∞–Ω—ã ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ–º –≥–æ—Ç–æ–≤—ã–π –ø—Ä–µ—Å–µ—Ç
        params["preset"] = preset or "traffic"

    if sort:
        params["sort"] = sort

    headers = {}
    if token:
        headers["Authorization"] = f"OAuth {token}"

    # --- –û—Å–Ω–æ–≤–Ω–∞—è –ª–æ–≥–∏–∫–∞ –≤—ã–≥—Ä—É–∑–∫–∏ ---
    # –†–∞–∑–±–∏–≤–∞–µ–º –æ–±—â–∏–π –¥–∏–∞–ø–∞–∑–æ–Ω –¥–∞—Ç –Ω–∞ —á–∞–Ω–∫–∏ (–Ω–µ–¥–µ–ª–∏/–º–µ—Å—è—Ü—ã/–≥–æ–¥—ã)
    date_chunks = list(auto_date_chunks(params["date1"], params["date2"], split=split))
    if not date_chunks:
        raise YandexMetrikaError("–ù–µ —É–¥–∞–ª–æ—Å—å —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å –¥–∏–∞–ø–∞–∑–æ–Ω—ã –¥–∞—Ç –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞")

    all_rows, query = [], None

    # –ü—Ä–æ—Ö–æ–¥–∏–º –ø–æ –∫–∞–∂–¥–æ–º—É –¥–∏–∞–ø–∞–∑–æ–Ω—É –¥–∞—Ç
    for d1, d2 in date_chunks:
        chunk_params = params.copy()
        chunk_params.update({"date1": d1, "date2": d2})

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤—Å–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ –¥–∏–∞–ø–∞–∑–æ–Ω–∞
        payload = fetch_chunk_all_pages(API_URL, chunk_params, headers, batch_size, max_rows)

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º query (—Å—Ç—Ä—É–∫—Ç—É—Ä—É –∑–∞–ø—Ä–æ—Å–∞) —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω —Ä–∞–∑
        if query is None:
            query = payload.get("query", {})

        # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç—Ä–æ–∫–∏ –≤ –æ–±—â–∏–π —Å–ø–∏—Å–æ–∫
        all_rows.extend(payload.get("data", []))

        # –ï—Å–ª–∏ –¥–æ—Å—Ç–∏–≥–Ω—É—Ç –æ–±—â–∏–π –ª–∏–º–∏—Ç —Å—Ç—Ä–æ–∫ ‚Äî –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –≤—ã–≥—Ä—É–∑–∫—É
        if max_rows and len(all_rows) >= max_rows:
            logging.warning(f"–î–æ—Å—Ç–∏–≥–Ω—É—Ç –æ–±—â–∏–π –ª–∏–º–∏—Ç max_rows={max_rows}, –æ—Å—Ç–∞–Ω–æ–≤–∫–∞ –≤—ã–≥—Ä—É–∑–∫–∏")
            all_rows = all_rows[:max_rows]
            break

    # –ï—Å–ª–∏ –¥–∞–Ω–Ω—ã—Ö –Ω–µ—Ç ‚Äî –≤—ã–±—Ä–∞—Å—ã–≤–∞–µ–º –∏—Å–∫–ª—é—á–µ–Ω–∏–µ
    if not all_rows:
        raise YandexMetrikaError("API –≤–µ—Ä–Ω—É–ª –ø—É—Å—Ç–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç ‚Äî –¥–∞–Ω–Ω—ã—Ö –Ω–µ—Ç –ø–æ –∑–∞–¥–∞–Ω–Ω—ã–º –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º")

    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ DataFrame
    df = build_dataframe({"data": all_rows, "query": query})

    # –ó–∞–º–µ—Ä—è–µ–º –æ–±—â–µ–µ –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
    elapsed = time.perf_counter() - start_time
    mem_mb = df.memory_usage(deep=True).sum() / (1024 * 1024)

    logging.info(
        f"–§–∏–Ω–∞–ª—å–Ω–∞—è —Å–≤–æ–¥–∫–∞: —Å—Ç—Ä–æ–∫={len(df)}, "
        f"–≤—Ä–µ–º—è={elapsed:.2f} —Å–µ–∫, "
        f"–ø–∞–º—è—Ç—å={mem_mb:.2f} –ú–ë"
    )

    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ –Ω—É–∂–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ
    if output_format == "json":
        return df.to_json(orient="records", force_ascii=False)
    else:
        return df.to_csv(index=False)


if __name__ == "__main__":
    tests = [
        {"ids": "44147844", "date1": "2024-01-01", "date2": "2024-01-07"},
        {"ids": "44147844", "date1": "2024-02-01", "date2": "2024-02-07", "metrics": "ym:s:visits"},
        {"ids": "44147844", "date1": "2024-03-01", "date2": "2024-03-31", "dimensions": "ym:s:regionCityName"},
        {"ids": "44147844", "date1": "2024-04-01", "date2": "2024-04-30", "preset": "traffic"},
        {"ids": "44147844", "date1": "2024-05-01", "date2": "2024-05-31", "sort": "-ym:s:visits"},
        {"ids": "44147844", "date1": "2024-06-01", "date2": "2024-06-30", "output_format": "json"},
        {"ids": "44147844", "date1": "2024-07-01", "date2": "2024-07-31", "batch_size": 5000},
        {"ids": "44147844", "date1": "2024-08-01", "date2": "2024-08-31", "max_rows": 100},
        {"ids": "44147844", "date1": "2024-09-01", "date2": "2024-09-30", "filters": "ym:s:regionCityName=='–ú–æ—Å–∫–≤–∞'"},
        {"ids": "44147844", "date1": "2024-10-01", "date2": "2024-10-31", "lang": "ru"},

        # üî• –ù–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å: —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è + —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ + –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–µ—Ç—Ä–∏–∫ –∏ –∏–∑–º–µ—Ä–µ–Ω–∏–π
        {
            "ids": "44147844",
            "date1": "2024-01-01",
            "date2": "2024-12-31",
            "metrics": "ym:s:visits,ym:s:users,ym:s:pageviews",
            "dimensions": "ym:s:regionCityName,ym:s:deviceCategory",
            "filters": "ym:s:regionCityName=='–ú–æ—Å–∫–≤–∞' AND ym:s:deviceCategory=='desktop'",
            "sort": "-ym:s:visits",
            "batch_size": 10000,
            "output_format": "csv"
        },

        # ‚ùå –ù–µ–≥–∞—Ç–∏–≤–Ω—ã–π —Ç–µ—Å—Ç: —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –º–µ—Ç—Ä–∏–∫–µ (API –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç)
        {
            "ids": "44147844",
            "date1": "2024-01-01",
            "date2": "2024-01-31",
            "metrics": "ym:s:visits",
            "filters": "ym:s:visits>100"  # –û—à–∏–±–∫–∞: —Ñ–∏–ª—å—Ç—Ä—ã —Ä–∞–±–æ—Ç–∞—é—Ç —Ç–æ–ª—å–∫–æ —Å dimensions
        },
    ]

    for i, args in enumerate(tests, start=1):
        print(f"\n=== –¢–µ—Å—Ç {i} ===")
        try:
            result = get_report_visits_yandex_metric(args)
            print("‚úÖ –£—Å–ø–µ—Ö, –ø–µ—Ä–≤—ã–µ —Å–∏–º–≤–æ–ª—ã –æ—Ç–≤–µ—Ç–∞:")
            print(str(result)[:300])
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞: {e}")